{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c8068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26678dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'model1_dataset.csv' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_model_data = pd.read_csv('dataset/model1_dataset.csv')\n",
    "    print(\"Dataset 'model1_dataset.csv' loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'model1_dataset.csv' not found. Please ensure the file is uploaded.\")\n",
    "    exit() # Exit if the file is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316de7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'has_purchased'\n",
    "if TARGET_COLUMN not in df_model_data.columns:\n",
    "    print(f\"Error: Target column '{TARGET_COLUMN}' not found in the dataset.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f157f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_model_data[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef6ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_from_features = [\n",
    "TARGET_COLUMN,\n",
    "'customer_id',\n",
    "'product_id',\n",
    "'product_name',          # Textual\n",
    "'product_description',   # Textual\n",
    "'purchase_count',        # CRITICAL: Removed due to data leakage\n",
    "# Columns below might be present from the original merge and are not intended as direct features\n",
    "'customer_name',\n",
    "'customer_email',\n",
    "'customer_address',\n",
    "'customer_phone_number',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3a608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_columns_to_drop = [col for col in columns_to_drop_from_features if col in df_model_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461aaef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns remaining in X (features set, after removing target and problematic/irrelevant columns):\n",
      "['age', 'city', 'preferred_product_id', 'category', 'brand', 'price', 'discount', 'storage', 'color', 'release_year', 'year_since_release', 'sales_factor']\n"
     ]
    }
   ],
   "source": [
    "X = df_model_data.drop(columns=actual_columns_to_drop)\n",
    "\n",
    "print(\"\\nColumns remaining in X (features set, after removing target and problematic/irrelevant columns):\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7bd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = []\n",
    "categorical_features = []\n",
    "\n",
    "for col in X.columns:\n",
    "    if X[col].dtype in ['int64', 'float64']:\n",
    "    # Explicitly define based on business logic and data type\n",
    "        if col in ['customer_age', 'product_base_price', 'product_default_discount','product_release_year', 'product_year_since_release', 'product_sales_factor']:\n",
    "            numerical_features.append(col)\n",
    "    # Assuming 'customer_preferred_product_id' is an ID and should be treated as categorical if it's not a true continuous number\n",
    "        elif col in ['customer_preferred_product_id']:\n",
    "            categorical_features.append(col)\n",
    "        else: # Catch any other numerical columns\n",
    "            numerical_features.append(col)\n",
    "    else: # Treat as categorical (object, bool, etc.)\n",
    "        categorical_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94be15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_features:\n",
    "    if col in X.columns and X[col].isnull().any():\n",
    "        X[col] = X[col].fillna(X[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbbf3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identified Numerical features: ['age', 'preferred_product_id', 'price', 'discount', 'release_year', 'year_since_release', 'sales_factor']\n",
      "Identified Categorical features: ['city', 'category', 'brand', 'storage', 'color']\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_features:\n",
    "    if col in X.columns and X[col].isnull().any():\n",
    "        X[col] = X[col].fillna('Missing') # Or X[col].mode()[0]\n",
    "\n",
    "print(f\"\\nIdentified Numerical features: {numerical_features}\")\n",
    "print(f\"Identified Categorical features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32a66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline(steps=[\n",
    "('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef27f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12ad539",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "('num', numerical_transformer, numerical_features),\n",
    "('cat', categorical_transformer, categorical_features)\n",
    "],\n",
    "remainder='drop' # Drop any columns not specified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0391d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418404d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded dataset saved as 'encoded_model1_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Gabungkan X dan y menjadi satu DataFrame\n",
    "df_encoded = X.copy()\n",
    "df_encoded[TARGET_COLUMN] = y\n",
    "\n",
    "# Simpan ke CSV\n",
    "df_encoded.to_csv('dataset/encoded_model1_dataset.csv', index=False)\n",
    "print(\"Encoded dataset saved as 'encoded_model1_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35fef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set size: 274707 rows\n",
      "Test set size: 68677 rows\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nTrain set size: {len(X_train)} rows\")\n",
    "print(f\"Test set size: {len(X_test)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6bd3768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Naive Bayes model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Naive Bayes model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa349aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68ccf06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.4978\n",
      "Precision: 0.4981\n",
      "Recall: 0.5864\n",
      "F1-Score: 0.5387\n",
      "ROC-AUC: 0.4990\n",
      "\n",
      "Sintaks untuk model Naive Bayes telah dibuat dan dieksekusi.\n",
      "Dataset yang digunakan adalah 'model1_dataset.csv'.\n",
      "Kolom 'has_purchased' adalah target, dan kolom-kolom lain yang relevan digunakan sebagai fitur.\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'predict_proba'):\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] # Probability of the positive class (1)\n",
    "else:\n",
    "    y_proba = None\n",
    "    print(\"Warning: predict_proba is not available for this model, skipping ROC-AUC calculation.\")\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "if y_proba is not None:\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "else:\n",
    "    print(\"ROC-AUC not calculated.\")\n",
    "\n",
    "print(\"\\nSintaks untuk model Naive Bayes telah dibuat dan dieksekusi.\")\n",
    "print(\"Dataset yang digunakan adalah 'model1_dataset.csv'.\")\n",
    "print(\"Kolom 'has_purchased' adalah target, dan kolom-kolom lain yang relevan digunakan sebagai fitur.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dan hasil evaluasi berhasil disimpan ke 'naive_bayes_model.pkl'.\n",
      "Hasil evaluasi model berhasil disimpan ke 'model_evaluation.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Simpan model dan hasil evaluasi ke dalam satu dictionary\n",
    "evaluation_results = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"f1_score\": f1_score(y_test, y_pred)\n",
    "}\n",
    "if y_proba is not None:\n",
    "    evaluation_results[\"roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "model_and_metrics = {\n",
    "    \"model\": model,\n",
    "    \"evaluation\": evaluation_results\n",
    "}\n",
    "\n",
    "# Simpan ke file .pkl\n",
    "with open('naive_bayes_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_and_metrics, f)\n",
    "print(\"Model dan hasil evaluasi berhasil disimpan ke 'naive_bayes_model.pkl'.\")\n",
    "\n",
    "# Simpan hasil evaluasi ke file teks\n",
    "with open('dataset/model_evaluation.txt', 'w') as f:\n",
    "    for metric, value in evaluation_results.items():\n",
    "        f.write(f\"{metric}: {value:.4f}\\n\")\n",
    "print(\"Hasil evaluasi model berhasil disimpan ke 'model_evaluation.txt'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8958f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, render_template_string, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cae0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and evaluation results\n",
    "with open('naive_bayes_model.pkl', 'rb') as f:\n",
    "    model_and_metrics = pickle.load(f)\n",
    "model = model_and_metrics['model']\n",
    "evaluation = model_and_metrics['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90b0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil nama fitur dari model pipeline\n",
    "feature_names = model.named_steps['preprocessor'].transformers_[0][2] + model.named_steps['preprocessor'].transformers_[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "867ddfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: C:\\Users\\User\\AppData\\Local/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken 2pbnehUeLOtB0htlrVKOrlYmUH0_2UDLiDAH3cZpPjP896ubA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d003668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
      "     ---------------------------------------- 9.9/9.9 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "     -------------------------------------- 731.2/731.2 kB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Collecting pyarrow>=7.0\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "     ---------------------------------------- 25.8/25.8 MB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Collecting tenacity<10,>=8.1.0\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting toml<2,>=0.10.1\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "     ------------------------------------ 207.6/207.6 kB 972.2 kB/s eta 0:00:00\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Collecting jsonschema>=3.0\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "     ---------------------------------------- 88.7/88.7 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Collecting attrs>=22.2.0\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "     -------------------------------------- 63.8/63.8 kB 686.9 kB/s eta 0:00:00\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.25.1-cp311-cp311-win_amd64.whl (231 kB)\n",
      "     -------------------------------------- 231.6/231.6 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Installing collected packages: toml, tenacity, smmap, rpds-py, pyarrow, attrs, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed altair-5.5.0 attrs-25.3.0 gitdb-4.0.12 gitpython-3.1.44 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 pyarrow-20.0.0 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.25.1 smmap-5.0.2 streamlit-1.45.1 tenacity-9.1.2 toml-0.10.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3b49e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 14:20:00.184 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.184 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\User\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.521 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-04 14:20:00.523 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.524 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.526 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.527 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.528 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.529 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.530 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.531 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.532 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.546 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.546 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.548 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.549 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.551 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.552 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.554 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.555 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.556 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.556 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.557 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.567 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.568 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-04 14:20:00.570 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Set page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Customer Purchase Prediction\",\n",
    "    page_icon=\"üõçÔ∏è\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    with open('naive_bayes_model.pkl', 'rb') as f:\n",
    "        model_and_metrics = pickle.load(f)\n",
    "    return model_and_metrics\n",
    "\n",
    "# Load model and evaluation metrics\n",
    "model_and_metrics = load_model()\n",
    "model = model_and_metrics['model']\n",
    "evaluation = model_and_metrics['evaluation']\n",
    "\n",
    "# App title\n",
    "st.title(\"üõçÔ∏è Customer Purchase Prediction\")\n",
    "st.markdown(\"### Predict if a customer will make a purchase based on their characteristics\")\n",
    "\n",
    "# Create two columns\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.subheader(\"Customer Information\")\n",
    "    customer_age = st.number_input(\"Customer Age\", min_value=18, max_value=100, value=30)\n",
    "    customer_preferred_product_id = st.number_input(\"Customer Preferred Product ID\", value=1)\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"Product Information\")\n",
    "    product_base_price = st.number_input(\"Product Base Price\", min_value=0.0, value=100.0)\n",
    "    product_default_discount = st.number_input(\"Product Default Discount (%)\", min_value=0.0, max_value=100.0, value=0.0)\n",
    "    product_release_year = st.number_input(\"Product Release Year\", min_value=2000, max_value=2025, value=2023)\n",
    "    product_year_since_release = 2025 - product_release_year\n",
    "    product_sales_factor = st.number_input(\"Product Sales Factor\", min_value=0.0, max_value=10.0, value=1.0)\n",
    "\n",
    "# Create predict button\n",
    "if st.button(\"Predict Purchase Likelihood\"):\n",
    "    # Create input data frame\n",
    "    input_data = pd.DataFrame({\n",
    "        'customer_age': [customer_age],\n",
    "        'product_base_price': [product_base_price],\n",
    "        'product_default_discount': [product_default_discount],\n",
    "        'product_release_year': [product_release_year],\n",
    "        'product_year_since_release': [product_year_since_release],\n",
    "        'product_sales_factor': [product_sales_factor],\n",
    "        'customer_preferred_product_id': [customer_preferred_product_id]\n",
    "    })\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_data)\n",
    "    prediction_proba = model.predict_proba(input_data)\n",
    "\n",
    "    # Show results\n",
    "    st.markdown(\"### Prediction Results\")\n",
    "    if prediction[0] == 1:\n",
    "        st.success(\"This customer is likely to make a purchase! üéØ\")\n",
    "    else:\n",
    "        st.error(\"This customer is unlikely to make a purchase üòî\")\n",
    "\n",
    "    # Show probability\n",
    "    st.markdown(\"### Purchase Probability\")\n",
    "    prob_no = prediction_proba[0][0]\n",
    "    prob_yes = prediction_proba[0][1]\n",
    "    \n",
    "    st.progress(prob_yes)\n",
    "    st.write(f\"Probability of Purchase: {prob_yes:.2%}\")\n",
    "\n",
    "# Show model metrics\n",
    "st.sidebar.header(\"Model Performance Metrics\")\n",
    "for metric, value in evaluation.items():\n",
    "    st.sidebar.metric(\n",
    "        label=metric.replace('_', ' ').title(),\n",
    "        value=f\"{value:.4f}\"\n",
    "    )\n",
    "\n",
    "# Add information about the model\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.markdown(\"\"\"\n",
    "### About this Model\n",
    "This is a Naive Bayes classifier trained to predict customer purchases based on various features.\n",
    "The model takes into account:\n",
    "- Customer age\n",
    "- Product pricing\n",
    "- Product age\n",
    "- Sales factors\n",
    "\"\"\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"Made with ‚ù§Ô∏è using Streamlit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
